{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SABE Model Results Comparison\n",
    "\n",
    "This notebook compares the results of three different modeling approaches for the SABE dataset:\n",
    "1. Linear regression with normalization and dummy variables\n",
    "2. Linear regression without dummy variables\n",
    "3. Decision tree models\n",
    "\n",
    "Each modeling approach was applied to three target variables:\n",
    "- minimental (objective cognitive measure)\n",
    "- memoria_subjetiva (subjective memory assessment)\n",
    "- coherencia (coherence between objective and subjective measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Performance Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with performance metrics for all models\n",
    "models = [\n",
    "    # Regression with normalization/dummies\n",
    "    {'target': 'memoria_subjetiva', 'model': 'Regression with dummies', 'R²': 0.1918, 'Adjusted R²': 0.1865, 'RMSE': 0.8990, 'MAE': 0.7025, 'n_predictors': 110},\n",
    "    {'target': 'minimental', 'model': 'Regression with dummies', 'R²': 0.3340, 'Adjusted R²': 0.3296, 'RMSE': 0.8161, 'MAE': 0.6770, 'n_predictors': 110},\n",
    "    {'target': 'coherencia', 'model': 'Regression with dummies', 'R²': 0.3302, 'Adjusted R²': 0.3259, 'RMSE': 0.8184, 'MAE': 0.6659, 'n_predictors': 108},\n",
    "    \n",
    "    # Regression without dummies\n",
    "    {'target': 'memoria_subjetiva', 'model': 'Regression without dummies', 'R²': 0.1861, 'Adjusted R²': 0.1821, 'RMSE': 0.9022, 'MAE': 0.7061, 'n_predictors': 81},\n",
    "    {'target': 'minimental', 'model': 'Regression without dummies', 'R²': 0.1358, 'Adjusted R²': 0.1315, 'RMSE': 0.9296, 'MAE': 0.7854, 'n_predictors': 82},\n",
    "    {'target': 'coherencia', 'model': 'Regression without dummies', 'R²': 0.1755, 'Adjusted R²': 0.1715, 'RMSE': 0.9080, 'MAE': 0.7474, 'n_predictors': 81},\n",
    "    \n",
    "    # Decision trees\n",
    "    {'target': 'memoria_subjetiva', 'model': 'Decision Tree', 'R²': 0.1303, 'Adjusted R²': None, 'RMSE': 1.2415, 'MAE': 0.9818, 'n_predictors': None},\n",
    "    {'target': 'minimental', 'model': 'Decision Tree', 'R²': 0.0898, 'Adjusted R²': None, 'RMSE': 1.8386, 'MAE': 1.5485, 'n_predictors': None},\n",
    "    {'target': 'coherencia', 'model': 'Decision Tree', 'R²': 0.9999, 'Adjusted R²': None, 'RMSE': 0.0027, 'MAE': 0.0001, 'n_predictors': None}\n",
    "]\n",
    "\n",
    "# Convert to dataframe\n",
    "metrics_df = pd.DataFrame(models)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize R² values across models and targets\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(x='target', y='R²', hue='model', data=metrics_df)\n",
    "plt.title('R² Comparison Across Models and Target Variables', fontsize=16)\n",
    "plt.xlabel('Target Variable', fontsize=14)\n",
    "plt.ylabel('R²', fontsize=14)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(title='Model Type', fontsize=12, title_fontsize=14)\n",
    "\n",
    "# Add value labels\n",
    "for i, p in enumerate(ax.patches):\n",
    "    ax.annotate(f'{p.get_height():.2f}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha = 'center', va = 'center', \n",
    "                xytext = (0, 9), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RMSE values across models and targets\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(x='target', y='RMSE', hue='model', data=metrics_df)\n",
    "plt.title('RMSE Comparison Across Models and Target Variables', fontsize=16)\n",
    "plt.xlabel('Target Variable', fontsize=14)\n",
    "plt.ylabel('RMSE', fontsize=14)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(title='Model Type', fontsize=12, title_fontsize=14)\n",
    "\n",
    "# Add value labels\n",
    "for i, p in enumerate(ax.patches):\n",
    "    ax.annotate(f'{p.get_height():.2f}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha = 'center', va = 'center', \n",
    "                xytext = (0, 9), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Important Predictors Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes with top predictors for each target variable and model type\n",
    "\n",
    "# Memoria Subjetiva predictors\n",
    "memoria_predictors = [\n",
    "    # Regression with dummies\n",
    "    {'variable': 'color_piel_3', 'model': 'Regression with dummies', 'coefficient': -0.1511, 'importance': 0.1511},\n",
    "    {'variable': 'tiene_depresion_2', 'model': 'Regression with dummies', 'coefficient': 0.1060, 'importance': 0.1060},\n",
    "    {'variable': 'uso_redes_sociales_informales_2', 'model': 'Regression with dummies', 'coefficient': -0.1019, 'importance': 0.1019},\n",
    "    {'variable': 'vejez_positiva_3', 'model': 'Regression with dummies', 'coefficient': -0.1001, 'importance': 0.1001},\n",
    "    {'variable': 'autopercepcion_salud', 'model': 'Regression with dummies', 'coefficient': -0.1224, 'importance': 0.1224},\n",
    "    {'variable': 'sintomas_ultimo_mes', 'model': 'Regression with dummies', 'coefficient': 0.1198, 'importance': 0.1198},\n",
    "    {'variable': 'percepcion_visual', 'model': 'Regression with dummies', 'coefficient': -0.1189, 'importance': 0.1189},\n",
    "    \n",
    "    # Regression without dummies\n",
    "    {'variable': 'uso_medios_digitales', 'model': 'Regression without dummies', 'coefficient': 0.0204, 'importance': 0.0204},\n",
    "    {'variable': 'circ_cintura', 'model': 'Regression without dummies', 'coefficient': -0.0129, 'importance': 0.0129},\n",
    "    {'variable': 'sintomas_ultimo_mes', 'model': 'Regression without dummies', 'coefficient': 0.1196, 'importance': 0.1196},\n",
    "    {'variable': 'autopercepcion_salud', 'model': 'Regression without dummies', 'coefficient': -0.1207, 'importance': 0.1207},\n",
    "    {'variable': 'percepcion_visual', 'model': 'Regression without dummies', 'coefficient': -0.1208, 'importance': 0.1208},\n",
    "    \n",
    "    # Decision trees\n",
    "    {'variable': 'sintomas_ultimo_mes', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.4561},\n",
    "    {'variable': 'percepcion_visual', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.1633},\n",
    "    {'variable': 'problemas_auditivos', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.1588},\n",
    "    {'variable': 'autopercepcion_salud', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.1350},\n",
    "    {'variable': 'nivel_educativo', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.0258}\n",
    "]\n",
    "\n",
    "# Minimental predictors\n",
    "minimental_predictors = [\n",
    "    # Regression with dummies\n",
    "    {'variable': 'salida_desastre', 'model': 'Regression with dummies', 'coefficient': -0.1034, 'importance': 0.1034},\n",
    "    {'variable': 'sabe_leer', 'model': 'Regression with dummies', 'coefficient': -0.1372, 'importance': 0.1372},\n",
    "    {'variable': 'cancer', 'model': 'Regression with dummies', 'coefficient': 0.0931, 'importance': 0.0931},\n",
    "    {'variable': 'nivel_educativo', 'model': 'Regression with dummies', 'coefficient': 0.1010, 'importance': 0.1010},\n",
    "    {'variable': 'participacion_fisica_salud_3', 'model': 'Regression with dummies', 'coefficient': 0.2176, 'importance': 0.2176},\n",
    "    {'variable': 'color_piel_3', 'model': 'Regression with dummies', 'coefficient': -0.1554, 'importance': 0.1554},\n",
    "    \n",
    "    # Regression without dummies\n",
    "    {'variable': 'enfermedad_mental', 'model': 'Regression without dummies', 'coefficient': -0.1109, 'importance': 0.1109},\n",
    "    {'variable': 'edad', 'model': 'Regression without dummies', 'coefficient': -0.1134, 'importance': 0.1134},\n",
    "    {'variable': 'nivel_educativo', 'model': 'Regression without dummies', 'coefficient': 0.1274, 'importance': 0.1274},\n",
    "    {'variable': 'usa_gafas', 'model': 'Regression without dummies', 'coefficient': 0.1090, 'importance': 0.1090},\n",
    "    {'variable': 'color_piel', 'model': 'Regression without dummies', 'coefficient': -0.1142, 'importance': 0.1142},\n",
    "    \n",
    "    # Decision trees\n",
    "    {'variable': 'sabe_escribir', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.4137},\n",
    "    {'variable': 'nivel_educativo', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.2804},\n",
    "    {'variable': 'edad', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.1130},\n",
    "    {'variable': 'comido_menos', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.0523},\n",
    "    {'variable': 'a_educacion', 'model': 'Decision Tree', 'coefficient': None, 'importance': 0.0390}\n",
    "]\n",
    "\n",
    "# Coherencia predictors\n",
    "coherencia_predictors = [\n",
    "    # Regression with dummies\n",
    "    {'variable': 'participacion_fisica_salud_3', 'model': 'Regression with dummies', 'coefficient': 0.2619, 'importance': 0.2619},\n",
    "    {'variable': 'nivel_educativo', 'model': 'Regression with dummies', 'coefficient': 0.1127, 'importance': 0.1127},\n",
    "    {'variable': 'seguridad_barrio', 'model': 'Regression with dummies', 'coefficient': -0.0188, 'importance': 0.0188},\n",
    "    {'variable': 'sabe_leer', 'model': 'Regression with dummies', 'coefficient': -0.1517, 'importance': 0.1517},\n",
    "    {'variable': 'no_esta_informado', 'model': 'Regression with dummies', 'coefficient': -0.1003, 'importance': 0.1003},\n",
    "    \n",
    "    # Regression without dummies\n",
    "    {'variable': 'nivel_educativo', 'model': 'Regression without dummies', 'coefficient': 0.1377, 'importance': 0.1377},\n",
    "    {'variable': 'problemas_auditivos', 'model': 'Regression without dummies', 'coefficient': -0.1129, 'importance': 0.1129},\n",
    "    {'variable': 'edad', 'model': 'Regression without dummies', 'coefficient': -0.1120, 'importance': 0.1120},\n",
    "    {'variable': 'enfermedad_mental', 'model': 'Regression without dummies', 'coefficient': -0.1155, 'importance': 0.1155},\n",
    "    {'variable': 'salida_desastre', 'model': 'Regression without dummies', 'coefficient': -0.1267, 'importance': 0.1267},\n",
    "    \n",
    "    # Decision trees\n",
    "    {'variable': 'circ_cintura', 'model': 'Decision Tree', 'coefficient': None, 'importance': 1.0},\n",
    "    {'variable': 'discriminacion_color_piel', 'model': 'Decision Tree', 'coefficient': None, 'importance': 1.0},\n",
    "    {'variable': 'impacto_salud_bucal', 'model': 'Decision Tree', 'coefficient': None, 'importance': 1.0},\n",
    "    {'variable': 'independencia_fuera', 'model': 'Decision Tree', 'coefficient': None, 'importance': 1.0},\n",
    "    {'variable': 'dependencia_economica', 'model': 'Decision Tree', 'coefficient': None, 'importance': 1.0},\n",
    "    {'variable': 'salida_economica', 'model': 'Decision Tree', 'coefficient': None, 'importance': 1.0},\n",
    "    {'variable': 'housing_satisfaction', 'model': 'Decision Tree', 'coefficient': None, 'importance': 1.0}\n",
    "]\n",
    "\n",
    "# Convert to dataframes\n",
    "memoria_predictors_df = pd.DataFrame(memoria_predictors)\n",
    "minimental_predictors_df = pd.DataFrame(minimental_predictors)\n",
    "coherencia_predictors_df = pd.DataFrame(coherencia_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to visualize predictors by target and model\n",
    "def plot_predictors(df, target_name):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Get unique models\n",
    "    models = df['model'].unique()\n",
    "    n_models = len(models)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(18, 6))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot for each model\n",
    "    for i, model in enumerate(models):\n",
    "        model_df = df[df['model'] == model].sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Plot horizontal bar chart\n",
    "        axes[i].barh(model_df['variable'], model_df['importance'], color='skyblue')\n",
    "        axes[i].set_title(f'{model}', fontsize=14)\n",
    "        axes[i].set_xlabel('Importance/Coefficient (abs)', fontsize=12)\n",
    "        \n",
    "        # Add coefficient values if available\n",
    "        for j, (var, imp, coef) in enumerate(zip(model_df['variable'], model_df['importance'], model_df['coefficient'])):\n",
    "            if pd.notna(coef):\n",
    "                sign = '+' if coef > 0 else ''\n",
    "                axes[i].text(imp + 0.01, j, f\"{sign}{coef:.2f}\", va='center')\n",
    "            else:\n",
    "                axes[i].text(imp + 0.01, j, f\"{imp:.2f}\", va='center')\n",
    "    \n",
    "    # Add overall title\n",
    "    fig.suptitle(f'Important Predictors for {target_name}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictors for each target variable\n",
    "plot_predictors(memoria_predictors_df, 'Memoria Subjetiva')\n",
    "plot_predictors(minimental_predictors_df, 'Minimental')\n",
    "plot_predictors(coherencia_predictors_df, 'Coherencia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find Common Predictors Across Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract common predictors for a target variable\n",
    "def find_common_predictors(df):\n",
    "    # Get all unique variables\n",
    "    all_vars = df['variable'].unique()\n",
    "    \n",
    "    # Count occurrences of each variable across models\n",
    "    var_counts = {}\n",
    "    for var in all_vars:\n",
    "        models_with_var = df[df['variable'] == var]['model'].unique()\n",
    "        var_counts[var] = len(models_with_var)\n",
    "    \n",
    "    # Convert to dataframe and sort\n",
    "    result = pd.DataFrame({\n",
    "        'variable': list(var_counts.keys()),\n",
    "        'count': list(var_counts.values())\n",
    "    })\n",
    "    result = result.sort_values('count', ascending=False)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common predictors for each target variable\n",
    "memoria_common = find_common_predictors(memoria_predictors_df)\n",
    "minimental_common = find_common_predictors(minimental_predictors_df)\n",
    "coherencia_common = find_common_predictors(coherencia_predictors_df)\n",
    "\n",
    "# Display results\n",
    "print(\"Common predictors for Memoria Subjetiva:\")\n",
    "print(memoria_common)\n",
    "\n",
    "print(\"\\nCommon predictors for Minimental:\")\n",
    "print(minimental_common)\n",
    "\n",
    "print(\"\\nCommon predictors for Coherencia:\")\n",
    "print(coherencia_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison of Predictors Across Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all predictors\n",
    "all_predictors = pd.concat([\n",
    "    memoria_predictors_df.assign(target='memoria_subjetiva'),\n",
    "    minimental_predictors_df.assign(target='minimental'),\n",
    "    coherencia_predictors_df.assign(target='coherencia')\n",
    "])\n",
    "\n",
    "# Find variables that appear in multiple target variables\n",
    "all_vars = all_predictors['variable'].unique()\n",
    "var_in_targets = {}\n",
    "\n",
    "for var in all_vars:\n",
    "    targets = all_predictors[all_predictors['variable'] == var]['target'].unique()\n",
    "    var_in_targets[var] = {\n",
    "        'count': len(targets),\n",
    "        'targets': ', '.join(targets)\n",
    "    }\n",
    "\n",
    "# Convert to dataframe and sort\n",
    "cross_target_vars = pd.DataFrame({\n",
    "    'variable': list(var_in_targets.keys()),\n",
    "    'count': [v['count'] for v in var_in_targets.values()],\n",
    "    'targets': [v['targets'] for v in var_in_targets.values()]\n",
    "})\n",
    "cross_target_vars = cross_target_vars.sort_values(['count', 'variable'], ascending=[False, True])\n",
    "\n",
    "# Display variables that appear in multiple target variables\n",
    "cross_target_vars[cross_target_vars['count'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model Performance Summary\n",
    "\n",
    "1. **Memoria Subjetiva**:\n",
    "   - All three modeling approaches showed similar R² values (0.19, 0.19, 0.13)\n",
    "   - Linear regression models (both with and without dummies) performed slightly better than the decision tree\n",
    "   - The best model explained approximately 19% of the variance in subjective memory assessment\n",
    "\n",
    "2. **Minimental**:\n",
    "   - Regression with dummies performed significantly better (R² = 0.33) than the other approaches\n",
    "   - Regression without dummies had modest performance (R² = 0.14)\n",
    "   - Decision tree performed poorly (R² = 0.09)\n",
    "\n",
    "3. **Coherencia**:\n",
    "   - Decision tree showed extremely high performance (R² = 0.9999), suggesting potential overfitting\n",
    "   - Regression with dummies performed moderately well (R² = 0.33)\n",
    "   - Regression without dummies had lower performance (R² = 0.18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Important Predictors Summary\n",
    "\n",
    "1. **Memoria Subjetiva**:\n",
    "   - Consistent predictors across models: `sintomas_ultimo_mes`, `percepcion_visual`, and `autopercepcion_salud`\n",
    "   - Health perception variables were consistently important across all modeling approaches\n",
    "   - Decision tree heavily emphasized `sintomas_ultimo_mes` (importance = 0.46)\n",
    "\n",
    "2. **Minimental**:\n",
    "   - Education-related variables (`nivel_educativo`, `sabe_leer`, `sabe_escribir`) were consistently important\n",
    "   - `edad` appeared in multiple models as a negative predictor\n",
    "   - `color_piel` variables showed significant associations in regression models\n",
    "\n",
    "3. **Coherencia**:\n",
    "   - `nivel_educativo` was important in both regression models\n",
    "   - Decision tree identified a different set of predictors with perfect prediction\n",
    "   - Health-related variables (`problemas_auditivos`, `enfermedad_mental`) showed importance in regression without dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Cross-Target Variable Predictors\n",
    "\n",
    "Several predictors appeared important across multiple target variables:\n",
    "\n",
    "1. `nivel_educativo`: Important for all three target variables\n",
    "   - Positive association with minimental (objective cognitive performance)\n",
    "   - Positive association with coherencia (alignment between objective and subjective measures)\n",
    "   - Less important but still present for memoria_subjetiva\n",
    "\n",
    "2. `edad`: Important for minimental and coherencia\n",
    "   - Negative association with both variables (older age → lower cognitive performance and lower coherence)\n",
    "\n",
    "3. `problemas_auditivos`: Important for memoria_subjetiva and coherencia\n",
    "   - Associated with both how people perceive their memory and the coherence between objective and subjective assessments\n",
    "\n",
    "4. `salida_desastre`: Important for minimental and coherencia in regression models\n",
    "   - Negative association with both variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Methodological Observations\n",
    "\n",
    "1. **Dummy Variables**:\n",
    "   - Using dummy variables in regression improved performance for minimental and coherencia\n",
    "   - The additional granularity from dummy variables captured important relationships\n",
    "\n",
    "2. **Decision Trees**:\n",
    "   - Poor performance for memoria_subjetiva and minimental\n",
    "   - Unexpectedly perfect performance for coherencia, suggesting potential overfitting or data issues\n",
    "   - Captured different variable relationships than linear models\n",
    "\n",
    "3. **Variable Importance**:\n",
    "   - Linear models and tree-based models identified somewhat different important predictors\n",
    "   - However, a core set of variables consistently appeared across modeling approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Key Conclusions\n",
    "\n",
    "1. **Predictability of Target Variables**:\n",
    "   - Objective cognitive performance (minimental) is more predictable than subjective memory assessment\n",
    "   - The best models explained about 33% of variance in minimental and coherencia\n",
    "   - Subjective memory assessment is more challenging to predict (only ~19% variance explained)\n",
    "\n",
    "2. **Important Factors**:\n",
    "   - Education level consistently emerges as a key factor across all aspects of cognitive assessment\n",
    "   - Health perception variables strongly influence subjective memory assessment\n",
    "   - Age negatively impacts both objective performance and coherence between measures\n",
    "   - Sensory issues (visual, auditory) play a role in memory self-assessment\n",
    "\n",
    "3. **Modeling Approach Considerations**:\n",
    "   - Linear regression with dummy variables offers the most consistent performance across target variables\n",
    "   - The decision tree result for coherencia requires further investigation (potential overfitting)\n",
    "   - Different modeling approaches provide complementary insights into predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Recommendations for Future Analysis\n",
    "\n",
    "1. **Model Refinement**:\n",
    "   - Investigate the extremely high decision tree performance for coherencia\n",
    "   - Consider more sophisticated models (random forests, gradient boosting) with proper cross-validation\n",
    "   - Explore interaction terms in regression models\n",
    "\n",
    "2. **Variable Selection**:\n",
    "   - Focus on the consistently important predictors identified across models\n",
    "   - Consider creating composite variables for related constructs\n",
    "\n",
    "3. **Target Variable Analysis**:\n",
    "   - Further investigate the relationship between objective and subjective memory measures\n",
    "   - Consider creating more specific coherence measures for different cognitive domains\n",
    "\n",
    "4. **Cross-Cultural Comparison**:\n",
    "   - Apply these models to SABE data from different countries to identify consistent patterns\n",
    "   - Explore cultural differences in predictors of subjective and objective memory assessment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}